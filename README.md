# GenAI-vs-Human-Hate

## Contributors
* Farnaz Asrari
* Steven Herrera
* Yueru Yan

## Introduction
Hate speech is not only generated by individuals but is now also produced by AI systems. We propose to explore the differences between human and AI generated hate speech and develop a model capable of distinguishing between the two. Our research question is:

_Can we accurately classify whether the implicit hate speech is generated by humans or AI?_

We will fine-tune on the following models:
* HateBert
* RoBERTa

We will use the following open source LLMs:
* _TODO_
* _TODO_
* _TODO_

## Datasets
1. [ToxiGen Dataset](https://arxiv.org/abs/2203.09509): A dataset of AI-generated toxic and hate speech targeting 13 groups, with 27.5k human validated rows.(Hartvigsen et al., 2022)
2. [Implicit Hate](https://paperswithcode.com/dataset/implicit-hate): The ElSherief et al. (2021) dataset includes 22,056 tweets from prominent U.S. extremist groups, with 6,346 tweets labeled as containing implicit hate speech and fine-grained annotations for each message and its implications.

## References
[ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection](https://aclanthology.org/2022.acl-long.234) (Hartvigsen et al., ACL 2022)
[Latent Hatred: A Benchmark for Understanding Implicit Hate Speech](https://aclanthology.org/2021.emnlp-main.29) (ElSherief et al., EMNLP 2021)
